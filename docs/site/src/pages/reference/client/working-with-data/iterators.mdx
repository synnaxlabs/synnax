---
layout: "@/layouts/Reference.astro"
title: "Iterators"
description: "Lazy evaluation for efficiently reading large datasets."
next: "Writers"
nextURL: "/reference/client/advanced/writers"
prev: "Streaming Data"
prevURL: "/reference/client/working-with-data/streaming-data"
---

import { Divider, Note } from "@synnaxlabs/pluto";
import { Fragment } from "react";
import { Client } from "@/components/client";
import { mdxOverrides } from "@/components/mdxOverrides";
export const components = mdxOverrides;

This guide covers using iterators for efficient lazy evaluation when reading large
datasets. Iterators allow you to process data in chunks without loading everything into
memory.

<Divider.Divider x />

## What are Iterators?

<Client.Tabs client:load exclude={["cpp","console"]}>
  <Fragment slot="console">
  </Fragment>

  <Fragment slot="python">
    <Note.Note variant="warning">

Single, multiple, and named reads will cover most use cases, but there are situations
where it's necessary to process more data than can be stored in memory.

Synnax supports server-side iterators that allow us to process large queries in
consistently sized chunks.

    </Note.Note>
  </Fragment>

  <Fragment slot="typescript">
    <Note.Note variant="info">

While the standard read methods will cover most use cases, there are situations where
it's necessary to query large volumes of data. Iterators provide a way to efficiently
process data in chunks to avoid keeping large amounts of data in memory.

    </Note.Note>
  </Fragment>
</Client.Tabs>

<Divider.Divider x />

## Creating an Iterator

<Client.Tabs client:load exclude={["cpp","console"]}>
  <Fragment slot="console">
  </Fragment>

  <Fragment slot="python">
    <Note.Note variant="warning">

To create an iterator, use the `client.open_iterator` method with a time range and
channel specification:

```python
with client.open_iterator(start, end, "my_precise_tc") as it:
    for frame in it:
        # Do something with the frame
```

The iterator is used as a context manager (`with` statement) to ensure proper cleanup of
resources when iteration is complete.

    </Note.Note>
  </Fragment>

  <Fragment slot="typescript">
    <Note.Note variant="info">

To create an iterator, use the `client.openIterator` method with a time range and
channel specification:

```typescript
const start = TimeStamp.now();
const end = start.add(TimeStamp.seconds(10));

const iterator = await client.openIterator(
  { start, end },
  ["temperature", "humidity"],
);
```

    </Note.Note>
  </Fragment>
</Client.Tabs>

<Divider.Divider x />

## Iterating through Data

<Client.Tabs client:load exclude={["cpp","console"]}>
  <Fragment slot="console">
  </Fragment>

  <Fragment slot="python">
    <Note.Note variant="warning">

Use a `for` loop to iterate through the data in chunks:

```python
with client.open_iterator(start, end, "my_precise_tc") as it:
    for frame in it:
        # Process each frame chunk
        print(frame)
```

Each iteration yields a frame containing a chunk of the data, allowing you to process
large datasets without loading everything into memory at once.

    </Note.Note>
  </Fragment>

  <Fragment slot="typescript">
    <Note.Note variant="info">

Use a `for await...of` loop to iterate through the data in chunks:

```typescript
const iterator = await client.openIterator(
  { start, end },
  ["temperature", "humidity"],
);
try {
  for await (const frame of iterator) {
    const temperature = frame.get("temperature");
    const humidity = frame.get("humidity");
    // Process the data
  }
} finally {
  iterator.close();
}
```

It's very important to `close` the iterator when you're done with it to free up network
resources. We highly recommend wrapping the iterator in a `try...finally` block to
ensure that it's closed properly in the event of an error.

    </Note.Note>
  </Fragment>
</Client.Tabs>

<Divider.Divider x />

## Iterator Configuration

<Client.Tabs client:load exclude={["cpp","console"]}>
  <Fragment slot="console">
  </Fragment>

  <Fragment slot="python">
    <Note.Note variant="warning">

By default, Synnax uses a chunk size of 100,000 samples. To configure a custom chunk
size, pass in the `chunk_size` argument to the `open_iterator` method with the desired
number of samples per iteration:

```python
with client.open_iterator(start, end, "my_precise_tc", chunk_size=100) as it:
    for frame in it:
        # Do something with the frame
```

Smaller chunk sizes reduce memory usage but may increase the number of network requests.
Larger chunk sizes can improve throughput but require more memory.

    </Note.Note>
  </Fragment>

  <Fragment slot="typescript">
    <Note.Note variant="info">

By default, Synnax uses a chunk size of 100,000 samples. To configure a custom chunk
size, set the `chunkSize` field in the options argument to the `openIterator` method
with the desired number of samples per iteration:

```typescript
const iterator = await client.openIterator(
  { start, end },
  ["temperature", "humidity"],
  {
    chunkSize: 100,
  },
);
try {
  for await (const frame of iterator) {
    const temperature = frame.get("temperature");
    const humidity = frame.get("humidity");
    // Process the data
  }
} finally {
  iterator.close();
}
```

Smaller chunk sizes reduce memory usage but may increase the number of network requests.
Larger chunk sizes can improve throughput but require more memory.

    </Note.Note>
  </Fragment>
</Client.Tabs>
