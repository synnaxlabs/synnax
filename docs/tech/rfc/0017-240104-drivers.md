# 16 - General Purpose Device Drivers

- **Feature Name**: General Purpose Device Drivers
- **Start Date**: 2024-01-04
- **Authors**: Emiliano Bonilla
- **Status**: Draft

# 5 - Detailed Design

## 5.0 - Overview

The highest level of the driver is called a driver. A driver manages a set of tasks,
which are in charge of acquiring data or executing commands on devices connected to the
computer the driver is running on. Tasks are completely independent of one another, are
only allowed to communicate with a single device, and can only perform data acquisition
or control, not both. The driver configures tasks based on a provided specification,
starts and stops tasks, and deletes them when they are no longer needed.

## 5.1 - The Driver

A driver represents a set of data acquisition and control tasks running within a single
program. A driver can interact with one or more devices. For example, a running instance
of the Synnax driver program would be represented by a driver data structure in the
cluster. A custom flight computer that communicates directly with Synnax over the
network could also register itself as a driver.

### 5.1.0 - Representation Inside the Synnax Server

A driver persists some of its metadata inside the Synnax Server for access by other
parts of the platform, such as the UI. Here are the fields we're going to store inside
Synnax:

```go
package irrelevant

type Driver struct {
    Key uint32
    Name string
}
```

The `Key` field would represent two composite `uint16s` where the first `uint16` is the
**leaseholder** of the driver i.e. which node the driver writes all of its data to. A
driver can write or read data from channels on any node, but must use this node as its
gateway for all communications. The second uint16 is simply an incrementing counter
identifying a particular driver within the scope of its leaseholder. For example, a
driver could be identified as `Node 5 Driver 2` or `Node 7 Driver 8`. Limiting the
number of drivers per node to 65535 is a little bit risky, but it helps make the key
much more compact.

### 5.3 - Driver Responsibilities

A driver has three responsibilities:

1. Discovering new devices and informing Synnax server of their existence.
2. Emitting a heartbeat at a consistent interval to communicate its health.
3. Configuring and commanding the acquisition and command tasks it's responsible for.

### 5.4.1 - Heartbeat

A driver emits a heartbeat over the `sy_driver_heartbeat` channel at a pre-determined
rate (we're setting this at 1 second to start). The heartbeat is 64-bit number, where
the first 32 bits are the key of the driver, and the second 32 bits are the version, a
number that is incremented every time the driver emits a heartbeat. Naturally, this
version resets to zero every time the driver restarts.

From an implementation perspective, the heartbeat mechanism will run on a separate
thread.

### 5.4.2 - Task Configuration

On startup, the driver starts listening on `sy_task_set` and `sy_task_delete` for task
creation, configuration, and deletion operations. Internally, the driver maintains a map
of task keys to their corresponding tasks. When a task is created or configured, the
driver looks for a task in the map with the same key. If one exists, that task is
stopped and removed from the map. The driver then re-configures the task, starts it, and
sets it back on the map. It's important to note that re-configuring a task involves the
re-allocation and re-construction of an entirely new data structure inside the driver.
This process is marginally more expensive than calling an `update` method with a new
configuration, but removes the complexity of needing to manage concurrent updates while
a task is running (advantage of purity).

Task configuration is a relatively infrequent (once every few seconds, at most)
operation, so it's totally fine to make the process more expensive for the sake of
keeping the system simple.

### 5.4.3 - Communicating Task State

- `sy_task_set` -> task configuration
- `sy_task_delete` -> task delete
- `sy_task_cmd` -> task state change
- `sy_task_state` -> task state response

## 5.0 - Command and Acquisition Pipelines

Driver functionality can be separated into two distinct pipelines: acquisition and
command. Acquisition pipelines acquire data from sensor hardware and forward it to
Synnax, while command pipelines receive commands from Synnax and execute them on the
hardware. This marks a clear point of design separation, and has a few beneficial
properties:

1. Command and acquisition pipelines don't need to share state (aside from what is
   implemented in hardware specific libraries like DAQmx).
2. The failure of a command pipeline should not affect the operation of an acquisition
   pipeline, and vice versa.

These two properties reduce the cognitive overhead, as both pipelines can be implemented
independently, only sharing essential primitives. Naturally, each pipeline should be
executed in its own thread.

## 5.1 - Acquisition Pipeline Overview

Acquisition pipelines operate as a continuous acquisition loop that performs three
tasks:

1. Acquire data from hardware.
2. Apply any necessary calibrations, transformations, taring.
3. Write data to Synnax.

This loop should run at a nearly-fixed rate, and consume a well-defined amount of CPU,
memory, and DAQ device resources (we'll touch more on timing later). From a high level,
implementing this loop seems quite simple. There are three emergent details that make it
far more difficult:

1. **Error handling** - Happy path execution is simple, but errors can occur in any of
   these steps. Some of these errors are critical and should halt pipeline execution,
   while some are transient and require retries or pipeline restarts. Correctly
   identifying, communicating, and handling these errors requires careful design.

2. **Configuration** - Every pipeline requires detailed configuration information to
   operate: channel names, physical device ports, calibrations, etc. These
   configurations are dynamic, and need to be updated mid-driver operation. Invalid
   configuration parameters are an additional source of errors, and need to be carefully
   communicated to and resolved by the user.

3. **Hardware 'Polymorphism'** - We're aiming to support DAQ hardware from a growing
   number of vendors, and, for the most part, the loop structure remains the same no
   matter the device. Ideally we'd make it possible to keep the majority of the pipeline
   code the same, and develop a standard interface for implementing step #1.

## 5.2 - Command Pipeline Overview

## 5.3 - Configuration

There are important properties and patterns to examine.

### 5.3.0 - Properties

#### 5.3.0.0 - Dynamism

Adaptive teams are always making changes to their system configuration: adding and
exchanging sensors, changing calibrations, and swapping DAQ tasks. From a user
perspective, these changes are quite frequent. During setup batched configuration
changes can come every few minutes. From a software, perspective, however, these changes
are _very_ infrequent. If a pipeline runs at 200hz and a configuration change comes
every ten minutes, that's 120,000 pipeline iterations between each application. Even
using 100 pipeline iterations (0.5s) to fetch and apply configuration changes would be
almost negligible to operation.

In consequence, it's worthwhile to make the configuration process more expensive to
achieve the following:

1. Improve the configuration process for the user by providing clear, reliable feedback.
2. Improve hot path (i.e. pipeline loop) performance and reduce complexity.

#### 5.3.0.1 - Flexibility

Different organizations configure different hardware in different ways. This makes it
largely impossible to define a fixed schema for configuration parameters; attempting to
do so would not only bloat the codebase, but result in very tight coupling between the
driver, core, and frontend.

#### 5.3.0.2 - Error Variants and Emergence

There are two levels of errors that can occur during configuration: critical and
warning. Critical errors mean the system can't operate, while warnings allow the system
to run but still must be communicated.

The more complex aspect of error handling is that configuration errors can occur at two
points: during pipeline setup and during pipeline execution. For example, the hardware
may validate the acquisition rate, but during runtime an ADC may not be able to keep
pace with the system.

### 5.4 - The Driver

#### 5.4.0 - Overview

### 5.5 - The Task

A task is an independent acquisition or control loop within a driver. Each task
communicates with a single device from a single vendor, and operates a command or
acquisition pipeline. The pipelines of a task have a consistent acquisition and command
acknowledgement rate. For example, a task could represent a continuous 100Hz acquisition
process from a National Instruments cDAQ.

By guaranteeing a single sample rate, a single device, and a single vendor, we can
considerably reduce the complexity ceiling of a task. We won't need to write code that
synchronizes timing or configuration between multiple devices from different vendors,
and we can complete all necessary tasks of a task with a single or small number of
threads.

Pseudocode for the data structure is as follows:

```go
package irrelevant

type Task struct {
   Key    uint64
   Name   string
   Type   string
   Config string
}

```

The `Key` field is two composite `uint32s`, where the first `uint32` is the key of a
task's driver, and the second is an incremented counter identifying a driver within its
task. As with a Driver, a task could be identified as `Node 5 Driver 2 Task 5`.

The`Type` field enables different task implementations to operate within the same
driver, and serves as the identifier fora driver side abstract factory to select and
configure the type's task class. The same pattern can be applied for any task specific
interfaces on the frontend.

Config is a JSON encoded string storing the configuration for that type of task. While
it reduces the amount of server side validation that can be completed on a task, it does
enable us to expand the number of DAQ vendors and add custom hardware without needing to
change Synnax Core.

We've debated about whether we should include the `config` field directly on the task
struct or not. Configuration info probably won't be very large (a few hundred kilobytes
at most), and it will be rare to query or list more tasks than a driver contains (which
is almost always less than 10). This is a two-way decision whose interface does not
affect the end user, so we can always move the config to its own struct if necessary.

## Working Notes

### How do we communicate task configuration and runtime errors?

1. Driver is in charge of starting, stopping, and

# 6 - Build System and CI

Perhaps the most challenging part of implementing a driver that can deal with devices
from multiple vendors is setting up a consistent build system for distribution across
multiple target platforms. It's already difficult to configure a C++ build system,
needing to deal with libraries like NI-DAQmx that are only available on Windows makes it
even more difficult.

## 6.0 - The Build System of Choice - Bazel

The reality is that there's no consistent, widely accepted way of building C++ software.
CMake and Bazel are the most common, modern systems. As always, there are lovers and
haters on each side. Our team has the most experience working with Bazel, so that's the
system we decided to go with.

The most relevant consequence of this decision is the challenge in distributing our C++
library to non-bazel projects. For now, this is a low priority issue, but it may become
more important in the future.

## 6.1 - Windows Driver Build Action

The GitHub action steps are:

1. Install the bazel-contrib/setup-bazel action.

2.
