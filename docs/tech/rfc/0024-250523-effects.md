# 24 - Effects

**Feature Name**: Effects <br /> **Status**: Complete <br /> **Start Date**:
2025-05-23 <br /> **Authors**: Emiliano Bonilla <br />

# 0 - Summary

In this RFC, we propose a new _effects_ feature for Synnax that allows for users to
listen to arbitrary events in Synnax and conditionally trigger actions based on those
events. As part of the implementation, I'll also propose a design for a new graphical
programming language called _Arc_ that serves as a foundation for extending Synnax's
automation capabilities.

# 1 - Motivation

Automation is a core component of Synnax's value proposition. Our current Python and Lua
based automations served as a good starting point. These implementations allowed
software savvy teams to perform almost any task, and gave us many months of valuable
feedback to understand what future automation capabilities should look like.

The earlier versions of Synnax are developer oriented, with the log-term goal of moving
towards more technician friendly interfaces as our user base grows. Now is the time to
start serious work towards this effort.

Motivation for an effects system arose from a desire to implement alarm capabilities in
Synnax. By listening to thresholds on one or more channels, we'd send a notification to
the user and/or perform an action such as setting the value of a channel.

While evaluating an implementation of alarm functionality, we started to see
commonalities between automated control sequences, calculations, and the logic necessary
to implement alarms. By implementing a new alarm feature, there would now be _four_ ways
to implement alarm functionality:

1. A Python script that consumes values from channels, checks if a threshold is crossed,
   and sets the value of a notification channel.
2. A Lua embedded sequence that does the same thing as #1.
3. A calculated channel that returns a notification string if a threshold is crossed.
4. The new alarm system where a user configures a specific condition, threshold, and
   action from the Console.

While a user tailored alarm dialog would be the most intuitive solution, the number of
distinct ways to implement the same functionality raises questions surrounding Synnax's
broader automation strategy.

The next section of this RFC reasons about this strategy, and proposes a new path
forward.

# 2 - Strategy

## 2.1 - Events and Actions

An automation is a sequence of actions triggered by a set of events. All events in
Synnax are represented by (A) a new value being written to a channel, or (B) a fixed
time interval.

(A) Changes in a channel's value can represent:

- A sensor value changing
- An actuator being activated
- A new data structure being create (i.e. range, channel, etc.)
- Control transfers
- State changes of tasks, sequences
- Users pressing buttons on schematics
- Arbitrary messages sent programmatically

(B) A fixed time interval represents:

- A loop iteration in a real-time control sequence
- A cron-job running at specific times

Categories (A) and (B) are not mutually exclusive. For example, time-based events can be
triggered by a channel receiving a timer message from a remote location.

A key characteristic is that there are a fundamentally limited set of easily
classifiable events.

Actions are more varied. Most are implement by writing values to channels, such as:

- Sending alarm notifications
- Commanding actuators
- Starting and stopping automations

But they can also be:

- Creating new data structures (i.e. range, channel, etc.)
- Sending messages over arbitrary protocols (Modbus, MQTT, Kafka, etc.)
- Performing jobs such as removing stale telemetry.

## 2.2 - Automation Execution Context & Runtimes

The `action -> event` flow does not provide a complete picture for the requirements of
an automation in the context of Synnax. It's also critical to understand the environment
an automation is executed in and the the constraints under which it must operate.

### 2.2.0 - General Execution Models

When building dynamically executed automations, there are four primary execution models:

1. **Step-Based Execution**: Automations are evaluated on a fixed time interval or
   "tick." At each tick, the system checks for event conditions and executes
   corresponding actions. This model is ideal for real-time control and monitoring
   scenarios where timing consistency is critical.

2. **Event-Driven Execution**: Automations are triggered immediately in response to
   event occurrences. For instance, when a value changes on a specific channel, the
   associated actions execute. This model excels in reactive systems that respond to
   sensor data, user input, or external messages with minimal latency.

3. **Fixed-Point Iteration**: Automations are continuously evaluated in a loop until a
   stable state is reachedâ€”i.e., until further evaluation produces no changes in state
   or outputs. This model is useful in scenarios where logic must converge, such as
   dependency resolution or stable control loops.

4. **Control Flow Interpretation**: Automations are represented as structured programs,
   with explicit logic constructs such as `if`, `while`, and `switch`. Execution follows
   the control path, allowing for complex procedural logic. This model is suited for
   implementing sophisticated logic flows and user-defined scripts.

### 2.2.1 - Practical Examples

Different automations in Synnax benefit from different execution models.

**Example 1 - Real-Time Control Loops**: A real-time control sequence such as a
bang-bang vale control loop must execute at a predictable time interval. This,
step-based execution model is comparable to our current, Lua based embedded control
sequences.

**Example 2 - Calculations**: A calculated channel must be executed when any of its
input parameters change. Running on a fixed time interval has the risk for
over-calculation on stale values or under-calculation by not re-running the calculation
if the values change too fast for the fixed time interval. An event-driven model is much
better suited for this use case, as it will re-run the calculation whenever values
change.

**Example 3 - Effects**: Pretty much the same story as calculations.

**Example 4 - Supervisory Procedures**: Supervisory procedures control overall execution
of an operation through a step of steps. A rocket engine test, for example, would have
setup, pressurization, redline checks, ignition, steady state, and shutdown steps. While
these can be modeled as separate states within a control loop, it's more natural to
understand them in a procedural manner with control flow to guard or change the
execution process across the steps. This type of automation is best modeled using
control flow interpretation, where blocks like `if`, `while`, and `switch` are used to
guard or change the execution process across the steps.

### 2.2.2 - Execution Context

As a parallel to runtimes, execution environments are also varied. Certain automations
lend themselves to running directly on real-time controllers in memory-predictable
languages like C or C++. Other automations, such as events or supervisory procedures,
benefit from flexible, event oriented languages like Go.

### 2.2.1 - Concurrency & Distribution

Larger scale automations, such as launch control systems or factories, contain dozens or
more concurrent process across networked devices that need to be coordinated. Tighly
controlled state machines, master coordination sequences, operator intervention, and
alarms/aborts all need to work in concert with each other.

When building an automation language for these use cases, it's critical to consider the
following:

1. **Simple Deployment**: Concurrent automations should be deployable across multiple
   target machines without the need for excessing manual configuration.
2. **Clear Process Flows**: The language should make it easy to understand the
   relationships between concurrent automation processes. Forking, controlling, and
   joining process across machines should be intuitive.
3. **Isolation**: Concurrent processes should be able to operate in independent,
   isolated execution environments, and can be considered self-contained units that do
   not require sharing of resources that restrict execution to a single machie (memory,
   file handles, locks, etc.)

## 2.2 - Multiple Interfaces for Defining Automations

If every automation is simply events triggering actions, shouldn't there be a single,
consolidated interface for defining them?

Probably not. A good user experience guides interactions towards the simplest path for
implementing the desired functionality. Part of this process involves restricting the
options available in order to simplify a workflow.

Take a Linear issue as an example. The `priority` field could just be defined as another
set of labels that can be added to the issue. By adding a specific field, however,
Linear is guiding the user towards the understanding that priority is a first class
field that probably should be defined. It also simplifies common tasks like filtration,
and visual grepping for issues by priority.

So, even though we could implement alarms by making the user write and run Python
scripts for everything, this functionality adds (1) a higher learning curve, (2) longer
implementation times, and (3) additional vectors for introducing bugs.

The conclusion here is that **we should** provide independent interfaces for performing
clearly distinct tasks. This doesn't necessarily mean that the implementation underneath
the hood should not be consolidated.

## 2.3 - Separation Between Interface, Specification, and Runtime

The next question is how to separate the interface, specification, and runtime of an
automation.

_Interface_ - How the user defines, monitors, and interacts with an automation.
_Specification_ - How the automation is stored and retrieved from Synnax. _Runtime_ -
Where and how the automation is executed.

In this next sections, I'll propose multiple interfaces for defining automations, a
single specification format for storing them, and multiple runtimes for executing them.

## 2.4 - A Single Specification & Source of Truth

If there is a limited set of possible events and actions, then it's natural to define a
single specification that can encapsulate every automated flow a user may want to run.
This is beneficial for a number of reasons:

1. **Single Source of Truth**: A single specification format allows for a single source
   of truth for all automations, regardless of the underlying runtime or superlying
   interface (graphical, table, text, etc.).
2. **Validation**: A single specification format allows for validation of all common
   expressions, control flow primitives, and other fundamental building blocks of the
   language.
3. **Debugging**: If we implement a graphical language that then transpiles into a
   unified specification, it's easy to identify the source of errors when debugging, as
   distinctions between flaws in the transpiled specification and the original graphical
   representation are clear.

### 2.4.1 - Text-Based Specification for Version Control

Perhaps the most important aspect of a single specification format is the ability to
version control arc automations in a single, consistent format. Text-based languages are
the standard for version control, and arc should be no different. All interfaces for
defining autoamtions should transpile into an underlying text-based representation.

## 2.5 - Runtimes for Executing Arc Specifications

With different execution models, it's natural to consider that different runtimes should
be used for executing different classes of automation. At the same time, it's preferable
to use a single runtime for all classes of automation, as it will drastically simplify
the implementation of Arc.

### 2.5.0 - Multiple Runtime Approach

The runtime is the final piece of the puzzle. As detailed in Section 2.2, different
runtimes perform better for different automations. As a result, we propose multiple
runtimes for executing Arc specifications depending on the automation type.

While runtimes will be implemented over time, the following three execution models will
cover all envisioned use cases for automations within Synnax:

1. **Event-Driven Runtime**: Used for calculations and effects, the event driven runtime
   will execute on the server to respond to changes in channel values and other events
   that occur throughout the cluster. **This will be the first runtime to be implemented
   for our alarms functionality.**

2. **Fixed-Point Iteration Runtime**: Used for real-time control loops, the fixed-point
   iteration runtime will execute on Synnax's device driver using a C++ runtime, and
   will be designed as a replacement for our current Lua based embedded control
   sequences that run on real-time operating systems.

3. **Control Flow Interpretation Runtime**: Used for supervisory procedures, the control
   flow runtime will allow for the execution of procedural logic that requires a higher
   degree of flexibility, but a lower degree of performance than the fixed-point
   iteration runtime. As this runtime is the closest to a general purpose programming
   language, it will be the most complex and last to be implemented.

The advantage of separate runtimes is direct and deep optimization of automations for a
specific use case. Implementing three language runtimes is incredibly problematic,
however.

### 2.5.1 - Single Runtime Approach

A single runtime is more preferable from a development and maintenance perspective. The
fundamental problem is: we have calculations and effects that execute on the server,
real-time control loops executing on the device driver, and supervisory procedures that
may execute in multiple locations. Building a single runtime that can execute across all
of these environments in a consistent manner is a significant challenge. Each operating
environment requires access to different primitives (channels in go, grpc sockets in
C++, etc.), so embedding external function calls for multiple languages is a path that
simply doesn't make sense for such a small development team.

#### 2.5.2 - Hybrid Runtime

Enter the hybrid approach, which involves leveraging a performant, existing runtime for
core language primitives (math expressions, control flow, memory management, etc.),
while relying on the embedding process for language and reactivity specific primitives.

Take, for example, a tightly controlled bang-bang control loop executing in soft-real
time on our device driver. The runtime would be responsible for the core logic: doing
comparisons against sensor values and determing actuator output values. The embedding
runtime (C++) would handle the timing of the the control loop, and would embed external
function calls to perform tasks such as command actuator output values and/or feed back
sensor values to the runtime.

One such candidate for the embedded runtime is [WebAssembly](https://webassembly.org/),
a bytecode format explicitly designed for embedding execution in other environments.
More on this in the design section.

## 3 - Design

### 3.0 - Two-Layer Architecture

Arc's design contains an event-based, inter-task orchestration layer followed by an
intra-task logic layer.

Fundamental idea: isolated tasks that communicate through channels.

#### 3.0.1 - L1 - Inter-Task Orchestration Layer

Layer 1 provides reactive data flow between isolated tasks. Tasks are triggered by
channel events and can be composed into complex automation pipelines.

```arc
// Sequential execution
start_cmd -> pressurization{
    ox_target: 500,
    fuel_target: 400
} -> ignition{
    duration: 10s
} -> shutdown{}

// Parallel execution with synchronization
enable -> [
    ox_control{setpoint: 500},
    fuel_control{setpoint: 400}
] -> all_stable -> ignition{}

// Conditional routing
sensor_data -> monitor{threshold: 100} -> [
    alarm: notify{severity: "high"},
    normal: log{}
]
```

#### 3.0.2 - L2 - Intra-Task Logic Layer

The intra-task layer executes logic within individual tasks. Each task is an isolated
unit with its own state and control flow.

```arc
task bang_bang{
    setpoint number
    sensor <-chan
    actuator ->chan
    deadband number
} () {
    // Stateful variable persists across executions
    last_state $= false

    value := <-sensor

    if value > (setpoint + deadband) {
        false -> actuator
        last_state $= false
    } else if value < (setpoint - deadband) {
        true -> actuator
        last_state $= true
    } else {
        // Within deadband - maintain state
        last_state -> actuator
    }
}
```

#### 3.0.3 - Task Definition and Invocation

Tasks are defined with configuration parameters (static) and runtime parameters
(dynamic):

```arc
// Task definition
task controller{
    // Configuration parameters - set at instantiation
    kp number           // Proportional gain
    ki number           // Integral gain
    setpoint number     // Target value
    sensor <-chan       // Input channel
    output ->chan       // Output channel
    interval timespan   // Execution rate
} (enable bool) {      // Runtime parameters - can change
    // Stateful variables for integral term
    integral $= 0
    last_time $= now()

    if !enable {
        0 -> output
        return
    }

    error := setpoint - (<-sensor)
    dt := now() - last_time
    integral $= integral + (error * dt)

    control := (kp * error) + (ki * integral)
    control -> output

    last_time $= now()
}

// Task invocation
start_button -> controller{
    kp: 1.5,
    ki: 0.1,
    setpoint: 100,
    sensor: temperature,
    output: heater_cmd,
    interval: 100ms
}(true)
```

#### 3.0.4 - Channel Operations and Data Flow

Channels are the primary communication mechanism between tasks:

```arc
// Basic channel operations
value -> channel          // Write
result := <-channel       // Blocking read
source -> destination     // Continuous piping

// Multi-channel operations
task aggregator{
    inputs []<-chan
    output ->chan
} () {
    sum := 0
    for input in inputs {
        sum += <-input
    }
    sum / len(inputs) -> output
}
```

#### 3.0.5 - Execution Models

Tasks support multiple execution models through configuration:

```arc
// Event-driven: Executes when channels receive data
task alarm{
    sensor <-chan
    threshold number
    alert ->chan
} () {
    if (<-sensor) > threshold {
        true -> alert
    }
}

// Interval-based: Executes at fixed intervals
task sampler{
    interval: 100ms
    source <-chan
    history ->chan
} () {
    (<-source) -> history
}

// Hybrid: Combines event and interval
task rate_limiter{
    interval: 1s
    input <-chan
    output ->chan
} () {
    last_value $= null

    // Non-blocking read with timeout
    select {
        case value := <-input:
            last_value $= value
        case <-timeout(interval):
            if last_value != null {
                last_value -> output
            }
    }
}
```

#### 3.0.6 - Built-in Tasks and Operators

Arc provides primitive tasks for common patterns:

```arc
// once: Single-shot trigger
once{start_signal} -> sequence{}

// delay: Time-based delay
trigger -> delay{duration: 5s} -> action{}

// filter: Conditional routing
data -> filter{
    condition: value > 0 && value < 100
} -> valid_range{}

// map: Transform values
sensor -> map{
    transform: (value * 9/5) + 32  // Celsius to Fahrenheit
} -> display{}

// reduce: Aggregate over time windows
stream -> reduce{
    window: 10s,
    operation: avg
} -> average{}
```

#### 3.0.7 - State Management

Tasks maintain isolated state through stateful variables:

```arc
task accumulator{
    input <-chan
    output ->chan
} () {
    // Stateful variables persist across invocations
    total $= 0
    count $= 0

    value := <-input
    total $= total + value
    count $= count + 1

    average := total / count
    average -> output
}
```

#### 3.0.8 - Error Handling

Tasks handle errors through channel-based error propagation:

```arc
task safe_divide{
    numerator <-chan
    denominator <-chan
    result ->chan
    error ->chan
} () {
    n := <-numerator
    d := <-denominator

    if d == 0 {
        "Division by zero" -> error
    } else {
        (n / d) -> result
    }
}
```
